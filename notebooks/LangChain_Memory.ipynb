{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LangChain hafıza sistemi yapay zeka uygulamaları için güçlü bir araçtır.Özelliklede sürekli etkileşim ve kullanıcıdan gelen geri bildirimle gelişebilen sistemler için.\n",
    "LangChain'de hafıza, genellikle kısa vadeli ve uzun vadeli olmak üzere iki ana kategoriye ayrılır.\n",
    "\n",
    "**Short-Term Memory**\n",
    "\n",
    "Kısa vadeli hafıza yalnızca aktif olan bir konuşma disizisi için geçerlidir ve bu hafıza yalnızca bir konuşma oturumu içinde hatırlanabilir.\n",
    "Bu hafıza her adımda güncellenir ve bağlamı takip eder.Bir sonraki adıma geçmeden önce mevcut konuşma durumunu okur ve güncellenmiş bilgiyi depolar.\n",
    "Kısa vadeli hafıza, ajanın önceki konuşmalardan öğrendiklerini hemen uygulamasına olanak tanır.\n",
    "\n",
    "**Long-Term Memory**\n",
    "\n",
    "Farklı konuşma dizileri arasında veri paylaşılmasını sağlar.Birden fazla oturumda veya konuşmada ki bilgileri saklar.\n",
    "\n",
    "**Memory Base Class**\n",
    "\n",
    "LangChain hafıza sistemleri genellikle bir temel sınıf olan BaseMemory sınıfından türetilir. Bu sınıf, hafıza yönetimi için gerekli temel fonksiyonları içerir. \n",
    "\n",
    "**load_memory_variables**: Bu fonksiyon, hafızadaki mevcut bilgileri yükler.\n",
    "\n",
    "**save_context**: Bu fonksiyon, bir adımın sonunda bilgileri hafızaya kaydeder.\n",
    "\n",
    "**clear_memory**: Bu fonksiyon, mevcut hafızayı temizler ve sıfırlar.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from secret_key import openapi_key\n",
    "from langchain_openai import OpenAI\n",
    "import os \n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = openapi_key\n",
    "\n",
    "llm = OpenAI(temperature=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n\\nHello! How are you doing today?'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"hello\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ConversationBufferMemory**\n",
    "\n",
    "Bu hafıza türü, bir konuşma sırasında geçen her türlü bilgiye dair verileri tutar. Bu veriler, konuşma dizisi boyunca sorular, yanıtlar ve bağlamları içerir.\n",
    "\n",
    "Konuşma sırasındaki her etkileşim kaydedilir ve konuşma sonlandırıldığında bu veriler hafızaya kaydedilir. Bir sonraki adımda bu bilgiler tekrar kullanılabilir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "from langchain.callbacks import get_openai_callback\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "conversation_bm = ConversationBufferMemory()\n",
    "Conversation_chain = ConversationChain(llm = llm,\n",
    "                                       memory =conversation_bm,\n",
    "                                       verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_tokens(chain,query):\n",
    "    with get_openai_callback() as cb:\n",
    "        result = chain.invoke(query)\n",
    "        print(f\"Spent a total of {cb.total_tokens} tokens\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Good Morning chat\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Good Morning chat',\n",
       " 'history': '',\n",
       " 'response': \" Good morning! It's a beautiful day outside, isn't it? The sun is shining and the birds are chirping. How are you feeling today?\"}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Conversation_chain(\"Good Morning chat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Good Morning chat\n",
      "AI:  Good morning! It's a beautiful day outside, isn't it? The sun is shining and the birds are chirping. How are you feeling today?\n",
      "Human: Do you remember what I wrote before?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Spent a total of 128 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Do you remember what I wrote before?',\n",
       " 'history': \"Human: Good Morning chat\\nAI:  Good morning! It's a beautiful day outside, isn't it? The sun is shining and the birds are chirping. How are you feeling today?\",\n",
       " 'response': ' Yes, I remember everything that has been said in our conversation so far. Would you like me to repeat something specific?'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_tokens(Conversation_chain,\"Do you remember what I wrote before?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Good Morning chat\n",
      "AI:  Good morning! It's a beautiful day outside, isn't it? The sun is shining and the birds are chirping. How are you feeling today?\n",
      "Human: Do you remember what I wrote before?\n",
      "AI:  Yes, I remember everything that has been said in our conversation so far. Would you like me to repeat something specific?\n",
      "Human: Can you briefly tell us about LLMs?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Spent a total of 259 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Can you briefly tell us about LLMs?',\n",
       " 'history': \"Human: Good Morning chat\\nAI:  Good morning! It's a beautiful day outside, isn't it? The sun is shining and the birds are chirping. How are you feeling today?\\nHuman: Do you remember what I wrote before?\\nAI:  Yes, I remember everything that has been said in our conversation so far. Would you like me to repeat something specific?\",\n",
       " 'response': ' LLMs stands for \"Large Language Models,\" which are machine learning models that are trained on large amounts of text data to understand and generate human language. They can be used for tasks such as language translation, text summarization, and question-answering. Some popular examples of LLMs include GPT-3, BERT, and T5. They have been making significant advancements in natural language processing and are being used in various industries such as customer service, content creation, and data analysis. Is there anything else you would like to know about LLMs?'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_tokens(Conversation_chain,\"Can you briefly tell us about LLMs?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(conversation_bm.buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ConversationSummaryMemory**\n",
    "\n",
    "Daha uzun konuşmaların önemli noktalarını özetler.Konuşma tamamlandığında, önemli bilgileri bir özet şeklinde hafızaya kaydeder. Bu özet, sistemin konuyu anlamasını kolaylaştırır.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryMemory\n",
    "from langchain.chains import ConversationChain\n",
    "\n",
    "memory_summary = ConversationSummaryMemory(llm = llm,max_token_limit  = 50)\n",
    "\n",
    "conversation = ConversationChain(llm = llm,\n",
    "                                  verbose = True,\n",
    "                                  memory = memory_summary )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Can you briefly tell us about LLMs?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Spent a total of 535 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Can you briefly tell us about LLMs?',\n",
       " 'history': '',\n",
       " 'response': ' Sure! LLM stands for \"Master of Laws\" and it is a postgraduate degree in law. It is usually pursued by individuals who already have a law degree and want to specialize in a specific area of law, such as tax law or international law. LLM programs can range from one to two years in length, depending on the country and institution. They typically involve coursework and may also require a thesis or research paper. LLMs are offered by many universities around the world and are recognized by legal employers as a valuable qualification. Did you have any other specific questions about LLMs?'}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_tokens(conversation,'Can you briefly tell us about LLMs?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ConversationBufferWindowMemory**\n",
    "\n",
    "Özellikle kısa vadeli hafızayı yönetmek için kullanılır. Bu hafıza, konuşma dizilerinin bir pencere uzunluğuna kadar verileri depolar ve genellikle, bir diyalogda önemli olan son birkaç adımı veya kullanıcı ile olan etkileşimin belirli bir kısmını tutar.\n",
    "\n",
    "Belirli bir penceredeki bilgileri tutar ve eski veriler otomatik olarak silinir. Bu pencere, yeni veriler geldikçe kaydırılır.Genellikle sistemin depolama alanını daha verimli kullanmasına yardımcı olur.\n",
    "\n",
    "Yeni bir etkileşim eklendiğinde, sistem eski verileri silip yeni verileri ekler ve böylece pencerede en son konuşma adımları güncel tutulur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "\n",
    "window_memory = ConversationBufferWindowMemory(k = 1)\n",
    "\n",
    "conversation = ConversationChain(llm = llm,\n",
    "                                 memory = window_memory,\n",
    "                                 verbose = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Can you briefly tell us about LLMs?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Spent a total of 216 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Can you briefly tell us about LLMs?',\n",
       " 'history': '',\n",
       " 'response': ' LLMs, or Language Model Libraries, are powerful AI tools used for natural language processing tasks. They consist of pre-trained models and algorithms that can understand and generate human language. LLMs are often used in various applications such as chatbots, language translation, and text summarization. They are constantly evolving and being improved upon by researchers and developers. Some popular LLMs include GPT-3, BERT, and XLNet. These models are trained on vast amounts of text data and are able to produce human-like responses and outputs. They have revolutionized the field of natural language processing and are widely used in industries such as marketing, customer service, and education. Is there anything else you would like to know about LLMs?'}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_tokens(conversation,\"Can you briefly tell us about LLMs?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
